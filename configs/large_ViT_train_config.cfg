#AI Cloud
tr_manifest_path: /home/student.aau.dk/saales20/local-global-Mul-Head-Attention/VIT_FSD50K/data_set/chunks_meta_dir/tr.csv
val_manifest_path: /home/student.aau.dk/saales20/local-global-Mul-Head-Attention/VIT_FSD50K/data_set/chunks_meta_dir/val.csv
eval_manifest_path: /home/student.aau.dk/saales20/local-global-Mul-Head-Attention/VIT_FSD50K/data_set/chunks_meta_dir/eval.csv
labels_map: /home/student.aau.dk/saales20/local-global-Mul-Head-Attention/VIT_FSD50K/data_set/chunks_meta_dir/lbl_map.json

audio_config:
    feature: melspectrogram
    # n_fft: 511
    # win_len:
    # hop_len:
    # normalize:
    sample_rate: 22050
    min_duration: 1
exp:
    exp_name: 40_epochs_train_lightning_ViT_classifier
    wandb: True
    wandb_api_key: 
    proj_name: Fourier-approximation-for-local-global-Multi-Head-Attention
    entity: ce8-840
    save_dir: /home/student.aau.dk/saales20/local-global-Mul-Head-Attention/VIT_FSD50K/model_checkpoints/
    log_freq: 10
    val_freq: 1
    log_to_file: False
    log_to_stdout: False

hparams:
    batch_size: 100
    n_epochs: 40
    scheduler:
        n_warmup: 5
    early_stopping_patience: 5 # end if no improvement after 5 epochs
    KWT:
        input_res: [96, 101] #shape of FSD50K spectograms
        patch_res: [96, 1]  # patch shape
        num_classes: 200 # number of classes 
        mlp_dim: 4096 # MLP dimensions. embedding_dim to mlp_dim ratio: 1:4
        dim: 1024  # number of embeddings
        heads: 16 # number of attention heads
        depth: 24 #depth of network
        # dropout: 0.0
        # emb_dropout: 0.1
        # pre_norm: False
        # pool: mean
    optimizer:
        lr: 0.0005 # learning rate
        betas: !!python/tuple [0.9, 0.98]
        eps: 0.000001
        weight_decay: 0.01


