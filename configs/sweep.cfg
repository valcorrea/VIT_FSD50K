
labels_map: C:\Users\vismi\Documents\University\datasets\FSD50K\manifests\lbl_map.json
tr_manifest_path: C:\Users\vismi\Documents\University\datasets\FSD50K\manifests\tr.csv
val_manifest_path: C:\Users\vismi\Documents\University\datasets\FSD50K\manifests\val.csv
eval_manifest_path: /home/student.aau.dk/zg27bp/datasets/covid19_cough/manifests/test_chunk.csv

exp:
    exp_name: sweeps_test
    wandb: True
    wandb_api_key:
    proj_name: sweep_tests
    entity: ce8-840
    save_dir: outputs/
    log_freq: 10
    val_freq: 1
    log_to_file: False
    log_to_stdout: False

audio_config:
    feature: melspectrogram
    sample_rate: 22050
    min_duration: 1

hparams:
    KWT:
        input_res: [96, 110]
        patch_res: [96, 1]
        num_classes: 200
        mlp_dim: 256
        dim: 64
        heads: 1
        depth: 12
    early_stopping_patience: 10

sweep:
    method: random #'grid','bayes'
    metric:
        name: val_loss_epoch #This can be anything. Loss, Accuracy, mAP. Just make sure the goal is set properly. We need to minimize loss but maximize accuracy.
        goal: minimize
    parameters:
        n_epochs: #You can add parameters that remain static throughout all the runs to log them
            value: 40
        dropout:
            values: [0.3, 0.4, 0.5]
        batch_size:
            distribution: q_log_uniform_values
            q: 8
            min: 32
            max: 256
        scheduler:
            values: [True, False]
        n_warmup:
            distribution: uniform
            min: 1
            max: 10
        optimizer:
            values: ['adam', 'sgd']
        betas: 
            value: !!python/tuple [0.9, 0.98]
        learning_rate:
            distribution: uniform
            min: 0
            max: 0.1

    